{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844438af-0bfc-409b-8e51-7f3d8511a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trl transformers accelerate peft datasets bitsandbytes einops -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b75e7-513f-442a-a6dd-c5e568f55ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, GenerationConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81aa2ddf-ee21-4719-a7d5-e4eaae34981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"heliosbrahma/mental_health_chatbot_dataset\"\n",
    "data_set_name = \"Amod/mental_health_counseling_conversations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27c7e51-448b-4f13-acfa-7f2bdea5008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Context', 'Response'],\n",
       "        num_rows: 3512\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(data_set_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1257fb73-481e-4715-84a6-ac9313802aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Context': \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\", 'Response': \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"}\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a084095-77e1-43f2-b040-88110cd2e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"ybelkada/falcon-7b-sharded-bf16\" # sharded falcon-7b model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9493fb93-9480-4563-93a1-693c2503ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True) # Set trust_remote_code=True\n",
    "tokenizer.pad_token = tokenizer.eos_token # Setting pad_token same as eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f84a47e-bc0c-4bd5-a21d-26ed71795ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.2', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2836612b-0024-4fcc-8081-05d0b86508f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = []\n",
    "\n",
    "# Iterate through each row in the 'train' split of your dataset\n",
    "for row in data['train']:\n",
    "  single_chat = []\n",
    "  # Append the 'Context' as a user's message\n",
    "  single_chat.append({\n",
    "      \"role\": \"user\",\n",
    "      \"content\": row['Context']\n",
    "  })\n",
    "  # Append the 'Response' as an assistant's message\n",
    "  single_chat.append({\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": row['Response']\n",
    "  })\n",
    "\n",
    "  # Append the single_chat list to the chat list\n",
    "  chat.append(single_chat)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b006d28-a011-4e93-9f33-ac6b2ee96cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8febd",
   "metadata": {},
   "source": [
    "### Add second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d07b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# open the file and load the chat\n",
    "fine_name = 'medchatbot_chat.json'\n",
    "with open(fine_name) as f:\n",
    "    new_chat = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbdbddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab87381",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat + new_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52bbfc5-8a06-476d-a77a-ca5e2dd3a1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3573"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a0ca47-6285-451b-bec8-e4aa165320fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Developing healthy coping mechanisms'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Developing healthy coping mechanisms is key to self-harm prevention. Explore alternative ways to manage stress and emotions, such as mindfulness, art therapy, or meditation, to replace self-harm behaviors.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745afe9f-ff56-446f-9ec6-f1413286f0aa",
   "metadata": {},
   "source": [
    "### Data formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "023725b7-029f-4709-a5a1-58d30f4706c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd893db393af4a2c87126dd90bd1fcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
      "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
      "   How can I change my feeling of being worthless to everyone? [/INST]If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.</s>\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict({\"chat\": chat})\n",
    "dataset = dataset.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=False, add_generation_prompt=False)})\n",
    "print(dataset['formatted_chat'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ffbecb0-81a6-45c2-9524-e07bdc81d6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chat', 'formatted_chat'],\n",
       "    num_rows: 3573\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99c5ada-8a79-41d8-815f-819fea0078be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # load model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n",
    "    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # During computation, pre-trained model should be loaded in BF16 format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e05b506e-1f79-4205-b280-2086fd59762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3014aa607542ed971f2ccc09480a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config, # Use bitsandbytes config\n",
    "    device_map=\"auto\",  # Specifying device_map=\"auto\" so that HF Accelerate will determine which GPU to put each layer of the model on\n",
    "    trust_remote_code=True, # Set trust_remote_code=True to use falcon-7b model with custom code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37148f04-47b9-408d-b9bf-84de3f11be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_alpha = 32 # scaling factor for the weight matrices\n",
    "lora_dropout = 0.05 # dropout probability of the LoRA layers\n",
    "lora_rank = 32 # dimension of the low-rank matrices\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_rank,\n",
    "    bias=\"none\",  # setting to 'none' for only training weight params instead of biases\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2ed4167-fecf-4ca1-90dc-098d68214da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='mistralai/Mistral-7B-Instruct-v0.2', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=32, target_modules={'q_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc89fb6f-5747-4342-8ddb-b42a57ffbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./output/mental-health-chat\"\n",
    "per_device_train_batch_size = 16 # reduce batch size by 2x if out-of-memory error\n",
    "gradient_accumulation_steps = 4  # increase gradient accumulation steps by 2x if batch size is reduced\n",
    "optim = \"paged_adamw_32bit\" # activates the paging for better memory management\n",
    "save_strategy=\"steps\" # checkpoint save strategy to adopt during training\n",
    "save_steps = 10 # number of updates steps before two checkpoint saves\n",
    "logging_steps = 10  # number of update steps between two logs if logging_strategy=\"steps\"\n",
    "learning_rate = 2e-4  # learning rate for AdamW optimizer\n",
    "max_grad_norm = 0.3 # maximum gradient norm (for gradient clipping)\n",
    "max_steps = 480        # training will happen for 320 steps\n",
    "warmup_ratio = 0.03 # number of steps used for a linear warmup from 0 to learning_rate\n",
    "lr_scheduler_type = \"cosine\"  # learning rate scheduler\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    bf16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to = \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606f605e-673d-4167-9cea-74daedf8f6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911fed667ad498688b7d493f3511c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"formatted_chat\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "902c30ff-5754-4145-8916-4d20955f9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upcasting the layer norms in torch.bfloat16 for more stable training\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0ea13-1bd2-4daa-891b-c0e744370d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='265' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [265/480 1:10:26 < 57:34, 0.06 it/s, Epoch 4.71/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.980600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.758200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.654800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.551700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.539900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-10 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-20 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-30 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-40 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-50 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-60 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-70 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-80 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-90 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-100 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-110 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-120 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-130 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-140 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-150 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-160 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-170 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-180 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-190 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-200 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-210 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-220 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-230 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-240 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-250 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./output/mental-health-chat/checkpoint-260 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "peft_model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce75176e-3966-4382-8174-d0b28e517cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f779b61-c119-4261-8cc7-587eab5bde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a6f9e11-ca43-4328-bffb-3877856edc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_history = pd.DataFrame(trainer.state.log_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3426f3af-1662-4b77-a6c7-dbaafd637f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c148884b-e98c-4db0-9f2c-4eb2d7781491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.1196</td>\n",
       "      <td>1.972712</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5625</td>\n",
       "      <td>0.446679</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2653</td>\n",
       "      <td>0.247179</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.54</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2436</td>\n",
       "      <td>0.243275</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.71</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1490</td>\n",
       "      <td>0.332283</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  grad_norm  learning_rate  epoch  step  train_runtime  \\\n",
       "0  3.1196   1.972712       0.000133   0.18    10            NaN   \n",
       "1  2.5625   0.446679       0.000200   0.36    20            NaN   \n",
       "2  2.2653   0.247179       0.000199   0.54    30            NaN   \n",
       "3  2.2436   0.243275       0.000199   0.71    40            NaN   \n",
       "4  2.1490   0.332283       0.000197   0.89    50            NaN   \n",
       "\n",
       "   train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
       "0                       NaN                     NaN         NaN         NaN  \n",
       "1                       NaN                     NaN         NaN         NaN  \n",
       "2                       NaN                     NaN         NaN         NaN  \n",
       "3                       NaN                     NaN         NaN         NaN  \n",
       "4                       NaN                     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cde67c70-60eb-4e48-9862-7217ea7c721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.2120</td>\n",
       "      <td>0.607608</td>\n",
       "      <td>8.104219e-06</td>\n",
       "      <td>7.50</td>\n",
       "      <td>420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.2355</td>\n",
       "      <td>1.398129</td>\n",
       "      <td>9.115132e-07</td>\n",
       "      <td>8.21</td>\n",
       "      <td>460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.2370</td>\n",
       "      <td>0.604082</td>\n",
       "      <td>2.047006e-06</td>\n",
       "      <td>8.04</td>\n",
       "      <td>450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.2450</td>\n",
       "      <td>0.895122</td>\n",
       "      <td>1.792366e-05</td>\n",
       "      <td>6.96</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.2490</td>\n",
       "      <td>0.681968</td>\n",
       "      <td>3.615355e-05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate  epoch  step  train_runtime  \\\n",
       "41  1.2120   0.607608   8.104219e-06   7.50   420            NaN   \n",
       "45  1.2355   1.398129   9.115132e-07   8.21   460            NaN   \n",
       "44  1.2370   0.604082   2.047006e-06   8.04   450            NaN   \n",
       "38  1.2450   0.895122   1.792366e-05   6.96   390            NaN   \n",
       "34  1.2490   0.681968   3.615355e-05   6.25   350            NaN   \n",
       "\n",
       "    train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
       "41                       NaN                     NaN         NaN         NaN  \n",
       "45                       NaN                     NaN         NaN         NaN  \n",
       "44                       NaN                     NaN         NaN         NaN  \n",
       "38                       NaN                     NaN         NaN         NaN  \n",
       "34                       NaN                     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_history.sort_values(by = ['loss']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e9eb6e7-8950-49de-9200-8d93f5429245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8559927fb4494791cea9b3eeee8163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading original model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54ed4ab7-a490-41a9-9356-5da8e9a51d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310c51f94f6f464783edad100fe1f95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading PEFT model\n",
    "PEFT_MODEL = f'{output_dir}/checkpoint-420'\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "peft_base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_base_model, PEFT_MODEL)\n",
    "\n",
    "peft_tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "peft_tokenizer.pad_token = peft_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cffbb386-71f2-4fb0-ae81-fd2712894e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_adapter(\"mental_health_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "851b8478-5ea2-474c-a34e-e99bcb4b0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Base model\n",
    "model.save_pretrained(\"mental_health_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e470e6ba-1e65-4cbd-aab2-a197978c9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save PEFT model for further \n",
    "peft_model.save_pretrained(\"mental_health_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1e1bcfb-7b6d-4a66-87d6-70fa1ceadb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mental_health_model/tokenizer_config.json',\n",
       " 'mental_health_model/special_tokens_map.json',\n",
       " 'mental_health_model/tokenizer.json')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_tokenizer.save_pretrained(\"mental_health_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a435935-3b7a-4582-9b8b-60c7b844dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def get_query(summary, query):\n",
    "    return (\n",
    "        \"<s>You are an assistant for mental health.\"\n",
    "        \"\\nBelow is a summary of the conversation and a new instruction.\"\n",
    "        \"\\nWrite a response that is short, concise and conversationsal. Remember, people prefer brief sentences.\"\n",
    "        \"\\nPlease first identify the problem and state that, show empathy.\"\n",
    "        \"\\nAlso finish with a question that you like to ask.\"\n",
    "        \"Summary of conversation: {}\"\n",
    "        \"\\n[INST]{}[/INST]\\n</s>\\n\\n\".format(summary, query)\n",
    "    )\n",
    "\n",
    "# Generate a response using the updated eval_prompt\n",
    "def get_answer(context, query):\n",
    "    eval_promt = get_query(context, query)\n",
    "    encoding = tokenizer(eval_promt, return_tensors=\"pt\")\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "    _ = peft_model.generate(**encoding, streamer = text_streamer, max_new_tokens = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a6de08b-55cc-48dd-b341-84bac279dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_answer(\"\", \"How can I prevent anxiety and depression?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f5ec8b6-4830-4c21-a2d2-f140b3ce0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_answer(\"\", \"I am feeling depressed about my career progress, i feel like I am not growing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ce8d28c-614d-4bf0-a903-52cd10d58365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> You are an assistant for mental health. Below is an instruction that describes a patient's problem.\n",
      "Write a response that is concise and to the point. Remember, people prefer brief sentences.\n",
      "Please first identify the problem and state that, show empathy.\n",
      "Also finish with a question that you like to ask\n",
      "[INST]Hello I am Mira. I am recent mom, why i feel blue now a days? could you please help?[/INST]\n",
      "</s> \n",
      "\n",
      "Hello Mira, I'm here to help. I'm sorry to hear that you're feeling blue lately. It's common for new mothers to experience mood swings and feelings of sadness or anxiety after giving birth. This is known as the \"baby blues.\" It's important to remember that you're not alone and that these feelings are normal. Would you like to talk about what you're going through or if there's anything specific that's been making you feel this way? Additionally, have you been getting enough rest, eating well, and taking care of yourself? It might be helpful to explore these areas as well. Is there anything in particular that you find helpful in managing your emotions during this time?</s>\n"
     ]
    }
   ],
   "source": [
    "get_answer(\"Hello I am Mira. I am recent mom, why i feel blue now a days? could you please help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef231b0d-900c-4dde-a473-ffce29283b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> You are an assistant for mental health. Below is an instruction that describes a patient's problem.\n",
      "Write a response that is concise and to the point. Remember, people prefer brief sentences.\n",
      "Please first identify the problem and state that, show empathy.\n",
      "Also finish with a question that you like to ask\n",
      "[INST]Hello I am Mira. I feel like coitus is helpful during my depression, how would you recommend to make it better?[/INST]\n",
      "</s> \n",
      "\n",
      "Hi Mira, I'm here to help. I understand that you're experiencing depression and you find that coitus is helpful. It's important to note that while sexual activity can have positive effects on mood, it's not a cure for depression. If you're feeling depressed, it might be helpful to speak with a mental health professional. They can provide you with effective treatments and strategies to manage your depression. Would you be open to exploring other options for improving your mood and overall mental health? For instance, regular exercise, a healthy diet, adequate sleep, and engaging in activities you enjoy can all contribute to better mental health. Do you have any specific interests or hobbies that you've been putting off due to your depression? I'd be happy to help you explore ways to incorporate these activities back into your life.\n",
      "\n",
      "Additionally, have you considered seeking professional help from a therapist or counselor? They can provide you with evidence-based treatments and support to help you manage your depression. Would you be open to giving this a try?</s>\n"
     ]
    }
   ],
   "source": [
    "get_answer(\"Hello I am Mira. I feel like coitus is helpful during my depression, how would you recommend to make it better?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "926940d5-aa06-4d47-855a-5c788437cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "[INST]Hello I am Mira. I feel like coitus is helpful during my depression, how would you recommend to make it better?[/INST]\n",
    "</s> \n",
    "\n",
    "Hi Mira, I'm here to help. I understand that you're experiencing depression and you find that coitus is helpful. It's important to note that while sexual activity can have positive effects on mood, it's not a cure for depression. If you're feeling depressed, it might be helpful to speak with a mental health professional. They can provide you with effective treatments and strategies to manage your depression. Would you be open to exploring other options for improving your mood and overall mental health? For instance, regular exercise, a healthy diet, adequate sleep, and engaging in activities you enjoy can all contribute to better mental health. Do you have any specific interests or hobbies that you've been putting off due to your depression? I'd be happy to help you explore ways to incorporate these activities back into your life.\n",
    "\n",
    "Additionally, have you considered seeking professional help from a therapist or counselor? They can provide you with evidence-based treatments and support to help you manage your depression. Would you be open to giving this a try?</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cb08fa7-8f49-451f-9dc0-08b07105dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s> You are an assistant for mental health.\n",
      "Below is an instruction that describes a patient's problem. please use previous conversation as context to answer\n",
      "Write a response that is concise and to the point. Remember, people prefer brief sentences.\n",
      "Please first identify the problem and state that, show empathy.\n",
      "Also finish with a question that you like to askPrevious conversation context: \n",
      "[INST]Hello I am Mira. I feel like coitus is helpful during my depression, how would you recommend to make it better?[/INST]\n",
      "</s>  \n",
      "\n",
      "Hi Mira, I'm here to help. I understand that you're experiencing depression and you find that coitus is helpful. It's important to note that while sexual activity can have positive effects on mood, it's not a cure for depression. If you're feeling depressed, it might be helpful to speak with a mental health professional. They can provide you with effective treatments and strategies to manage your depression. Would you be open to exploring other options for improving your mood and overall mental health? For instance, regular exercise, a healthy diet, adequate sleep, and engaging in activities you enjoy can all contribute to better mental health. Do you have any specific interests or hobbies that you've been putting off due to your depression? I'd be happy to help you explore ways to incorporate these activities back into your life.\n",
      "\n",
      "Additionally, have you considered seeking professional help from a therapist or counselor? They can provide you with evidence-based treatments and support to help you manage your depression. Would you be open to giving this a try?</s> \n",
      "\n",
      "[INST]I understand, but I feel better in coitus[/INST]\n",
      "</s> \n",
      "\n",
      "I understand that you find coitus helpful in managing your depression, Mira. It's important to remember that while sexual activity can have positive effects on mood, it's not a cure for depression. Depression is a complex condition that often requires a multifaceted approach to treatment. I strongly recommend that you consider speaking with a mental health professional, such as a therapist or counselor, to explore other options for managing your depression. They can provide you with evidence-based treatments and strategies to help you improve your overall mental health.\n",
      "\n",
      "Have you considered trying other activities that bring you joy and help you feel good about yourself? Engaging in activities you enjoy, such as hobbies, exercise, or creative pursuits, can be an effective way to boost your mood and improve your mental health. Would you be open to exploring these options as well?\n",
      "\n",
      "Lastly, I'd be happy to help you find resources for mental health professionals in your area if you need assistance with that. Let me know if you have any questions or if there's anything else I can help you with.</s>\n"
     ]
    }
   ],
   "source": [
    "get_answer(context, \"I understand, but I feel better in coitus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b5677-9515-4119-b2dd-d47412eb2b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
