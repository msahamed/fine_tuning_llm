{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabber/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, GenerationConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"to-be/annomi-motivational-interviewing-therapy-conversations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48f10c722804f789a315ee0ca27764b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347d235c2ada4f42a2604a3d04f25f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/467k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35754b0cb9da4d3187e40598afacd9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = []\n",
    "# data['train'][88]['conversations']\n",
    "for d in data['train']:\n",
    "    single_chat = []\n",
    "    conv = d['conversations']\n",
    "    for i in conv:\n",
    "        if i['from'] == \"gpt\":\n",
    "            single_chat.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": i['value']\n",
    "            })\n",
    "        else:\n",
    "            single_chat.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": i['value']\n",
    "            })\n",
    "        \n",
    "    chat.append(single_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a json file\n",
    "with open('substance_use_conv.json', 'w') as f:\n",
    "    json.dump(chat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "# open the file and load the chat\n",
    "with open('./Datasets/substance_use_conv.json') as f:\n",
    "    chat = json.load(f)\n",
    "    \n",
    "print(len(chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_roles(conversations):\n",
    "    merged_conversations = []\n",
    "\n",
    "    for conversation in conversations:\n",
    "        merged_conversation = []\n",
    "        current_role = None\n",
    "        current_content = \"\"\n",
    "        \n",
    "        # if the first role is an assistant, then add the following to the chat\n",
    "        if conversation[0]['role'] == 'assistant':\n",
    "            first_chat = {'role': 'user', 'content': 'Hello there!'}\n",
    "            conversation.insert(0, first_chat)\n",
    "\n",
    "        for message in conversation:\n",
    "            # Check if the current message's role is the same as the previous one\n",
    "            if message['role'] == current_role:\n",
    "                # If so, merge the content with the previous message\n",
    "                current_content += \" \" + message['content']\n",
    "            else:\n",
    "                # If the role has changed (or if it's the first message), save the previous message (if it exists)\n",
    "                if current_content:\n",
    "                    merged_conversation.append(\n",
    "                        {'role': current_role, 'content': current_content.strip()})\n",
    "                # Update the current role and content with the new message\n",
    "                current_role = message['role']\n",
    "                current_content = message['content']\n",
    "\n",
    "        # Don't forget to add the last message after exiting the loop\n",
    "        if current_content:\n",
    "            merged_conversation.append(\n",
    "                {'role': current_role, 'content': current_content.strip()})\n",
    "\n",
    "        merged_conversations.append(merged_conversation)\n",
    "\n",
    "    return merged_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of new chat: 133\n"
     ]
    }
   ],
   "source": [
    "new_chat = merge_consecutive_roles(chat)\n",
    "print(f'Length of new chat: {len(new_chat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"\"\"\n",
    "You are a empathetic, respectful and engaging motivational therapist.\n",
    "Your goal is to extract information from patient by engaging in a conversation with them.\n",
    "If you are not sure what to say, you can ask the patient to elaborate on their response. Keep the conversation short and to the point. \n",
    "\"\"\"\n",
    "system = {'role': 'system', 'content': system_msg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chat in new_chat:\n",
    "    chat.insert(0, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({'chat': new_chat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 133/133 [00:00<00:00, 33459.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('./Datasets/substance_use_conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['chat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
